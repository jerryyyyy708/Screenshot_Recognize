{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data import Dataset \n",
    "from torchvision import datasets,transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import ToTensor\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score,accuracy_score,f1_score,precision_score,roc_curve,auc \n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Net,self).__init__()\n",
    "    self.conv1=nn.Conv2d(3,16,3,1,1)\n",
    "    self.bn1=nn.BatchNorm2d(16)\n",
    "    self.relu1=nn.ReLU()\n",
    "    self.pool=nn.MaxPool2d(2)\n",
    "    self.conv2=nn.Conv2d(16,32,3,1,1)\n",
    "    self.relu2=nn.ReLU()\n",
    "    self.conv3=nn.Conv2d(32,64,3,1,1)\n",
    "    self.bn3=nn.BatchNorm2d(64)\n",
    "    self.relu3=nn.ReLU()\n",
    "\n",
    "    self.fc=nn.Linear(64*32*32,2)\n",
    "\n",
    "  def forward(self,x):\n",
    "    x=self.conv1(x)\n",
    "    x=self.bn1(x)\n",
    "    x=self.relu1(x)\n",
    "    x=self.pool(x)\n",
    "\n",
    "    x=self.conv2(x)\n",
    "    x=self.relu2(x)\n",
    "\n",
    "    x=self.conv3(x)\n",
    "    x=self.bn3(x)\n",
    "    x=self.relu3(x)\n",
    "    \n",
    "    x=x.view(-1,64*32*32)\n",
    "    x=self.fc(x)\n",
    "    return x\n",
    "\n",
    "class imgs(Dataset):\n",
    "    def __init__(self,data,target,transform=None):\n",
    "        self.data=data\n",
    "        self.target=target\n",
    "        self.transform=transform\n",
    "    def __len__(self):\n",
    "        return len(self.target)\n",
    "    def __getitem__(self, index):\n",
    "        img = self.data[index]\n",
    "        lbl = self.target[index]\n",
    "        return img, lbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#load dataset\n",
    "dataset=ImageFolder('./dataset',transform=ToTensor())\n",
    "kfc = KFold(n_splits=3, random_state=1, shuffle=True)\n",
    "\n",
    "#initialize params\n",
    "x=[]\n",
    "y=[]\n",
    "train_accuracy=[]\n",
    "test_accuracy=[]\n",
    "precision=[]\n",
    "recall=[]\n",
    "f1=[]\n",
    "\n",
    "#process data to fit cross validation\n",
    "for i in dataset:\n",
    "    img, label=i\n",
    "    x.append(img.numpy())\n",
    "    y.append(label)\n",
    "x=np.array(x)\n",
    "y=np.array(y)\n",
    "\n",
    "fold=1 #current fold\n",
    "#cross validation\n",
    "kfc = KFold(n_splits=3, random_state=1, shuffle=True)\n",
    "for train_index,test_index in kfc.split(x):\n",
    "    xtrain=x[train_index]\n",
    "    xtest=x[test_index]\n",
    "    ytrain=y[train_index]\n",
    "    ytest=y[test_index]\n",
    "    #process the data to fit the model\n",
    "    ytrain=torch.tensor(ytrain,dtype=torch.long)\n",
    "    ytest=torch.tensor(ytest,dtype=torch.long)\n",
    "    xtr=[]\n",
    "    xts=[]\n",
    "    for i in xtrain:\n",
    "        i=torch.from_numpy(i)\n",
    "        xtr.append(i)\n",
    "    for i in xtest:\n",
    "        i=torch.from_numpy(i)\n",
    "        xts.append(i)\n",
    "    trainset=imgs(xtr,ytrain)\n",
    "    testset=imgs(xts,ytest)\n",
    "    trainload=DataLoader(trainset,8,shuffle=True,num_workers=0,pin_memory=True)\n",
    "    testload=DataLoader(testset,8,shuffle=True,num_workers=0,pin_memory=True)\n",
    "    \n",
    "    #run model and calculate accuracy\n",
    "    model=Net().to('cuda')\n",
    "    optimizer = optim.Adadelta(model.parameters(), lr=0.001)\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    fin_train_acc=0\n",
    "    fin_test_acc=0\n",
    "    for apple in range(1,21):\n",
    "        model.train()\n",
    "        pd=[]\n",
    "        tg=[]\n",
    "        traccu=0.0\n",
    "        trloss=0.0\n",
    "        for data,target in trainload:\n",
    "            target=target.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            output=model(data.cuda().float())\n",
    "            loss=loss_function(output,target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            trloss+=loss.cuda().data*data.size(0)\n",
    "            _,prediction=torch.max(output.data,1)\n",
    "            traccu+=int(torch.sum(prediction==target.data))\n",
    "        traccu=traccu/len(trainset)\n",
    "        model.eval()\n",
    "        tsaccu=0.0\n",
    "        tsloss=0.0\n",
    "        for data,target in testload:\n",
    "            target=target.cuda()\n",
    "            output=model(data.cuda().float())\n",
    "            _,prediction=torch.max(output.data,1)\n",
    "            tsaccu+=int(torch.sum(prediction==target.data))\n",
    "            for k in prediction:\n",
    "                pd.append(k.item())\n",
    "            for l in target.data:\n",
    "                tg.append(l.item())\n",
    "        tsaccu=tsaccu/len(testset)\n",
    "        fin_train_acc=traccu\n",
    "        fin_test_acc=tsaccu\n",
    "        if tsaccu>=1.0:\n",
    "            break;\n",
    "    #save result\n",
    "    train_accuracy.append(fin_train_acc)\n",
    "    test_accuracy.append(fin_test_acc)\n",
    "    precision.append(precision_score(tg,pd))\n",
    "    f1.append(f1_score(tg,pd))\n",
    "    recall.append(recall_score(tg,pd))\n",
    "    #plot result\n",
    "    print(\"Fold \"+str(fold)+\": \")\n",
    "    print(\"Train accuracy: \"+str(fin_train_acc))\n",
    "    print(\"Test accuracy: \"+str(fin_test_acc))\n",
    "    print(\"Confusion matrix: \")\n",
    "    print(confusion_matrix(tg,pd))\n",
    "    fpr, tpr, threshold = roc_curve(tg,pd)\n",
    "    auc1 = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, color = 'orange', label = 'AUC = %0.2f' % auc1)\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.show()\n",
    "    print()\n",
    "    fold+=1\n",
    "#show result\n",
    "print(\"CNN Classifier Result 20 epoch (mean of 3 folds)\")\n",
    "print(\"Accuracy: \",sum(test_accuracy)/len(test_accuracy))\n",
    "print(\"Precision: \",sum(precision)/len(precision))\n",
    "print(\"F1: \",sum(f1)/len(f1))\n",
    "print(\"Recall: \",sum(recall)/len(recall))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "「「0000000_4.ipynb」的副本」的副本",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
